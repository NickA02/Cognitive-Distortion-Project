{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Cleaning and Evaluation for Binary Cognitive Distortion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Make this your results directory\n",
    "os.chdir('/Users/ulugsali/Desktop/Cognitive-Distortion-Project/results/')\n",
    "eval_path = 'multiclass/baseline/llama3.1-8b/zero_shot.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My husband works a lot which really helps our ...</td>\n",
       "      <td>Mental Filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I used to get many strange looks for the thing...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moved to another state left everything for my ...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It has been more than a year now , I feel alon...</td>\n",
       "      <td>Mind Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My sister has autism spectrum disorder, she al...</td>\n",
       "      <td>Mind Reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>From India: My brother is 40 years old and he ...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>From the U.S.: I was sexually abused and raped...</td>\n",
       "      <td>All-or-Nothing Thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>My grandsons personality has changed in every ...</td>\n",
       "      <td>Overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>From Egypt: I was diagnosed with OCD by my doc...</td>\n",
       "      <td>Emotional Reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>I met a my best friend when I was 16 and we st...</td>\n",
       "      <td>Labeling.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Prompt  \\\n",
       "0    My husband works a lot which really helps our ...   \n",
       "1    I used to get many strange looks for the thing...   \n",
       "2    Moved to another state left everything for my ...   \n",
       "3    It has been more than a year now , I feel alon...   \n",
       "4    My sister has autism spectrum disorder, she al...   \n",
       "..                                                 ...   \n",
       "501  From India: My brother is 40 years old and he ...   \n",
       "502  From the U.S.: I was sexually abused and raped...   \n",
       "503  My grandsons personality has changed in every ...   \n",
       "504  From Egypt: I was diagnosed with OCD by my doc...   \n",
       "505  I met a my best friend when I was 16 and we st...   \n",
       "\n",
       "                    Response  \n",
       "0              Mental Filter  \n",
       "1         Overgeneralization  \n",
       "2         Overgeneralization  \n",
       "3               Mind Reading  \n",
       "4               Mind Reading  \n",
       "..                       ...  \n",
       "501       Overgeneralization  \n",
       "502  All-or-Nothing Thinking  \n",
       "503       Overgeneralization  \n",
       "504      Emotional Reasoning  \n",
       "505                Labeling.  \n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "inference_df = pd.read_csv(eval_path)\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix Common Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My husband works a lot which really helps our ...</td>\n",
       "      <td>mental filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I used to get many strange looks for the thing...</td>\n",
       "      <td>overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Moved to another state left everything for my ...</td>\n",
       "      <td>overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It has been more than a year now , I feel alon...</td>\n",
       "      <td>mind reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>My sister has autism spectrum disorder, she al...</td>\n",
       "      <td>mind reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>From India: My brother is 40 years old and he ...</td>\n",
       "      <td>overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>From the U.S.: I was sexually abused and raped...</td>\n",
       "      <td>all-or-nothing thinking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>My grandsons personality has changed in every ...</td>\n",
       "      <td>overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>From Egypt: I was diagnosed with OCD by my doc...</td>\n",
       "      <td>emotional reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>I met a my best friend when I was 16 and we st...</td>\n",
       "      <td>labeling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Prompt  \\\n",
       "0    My husband works a lot which really helps our ...   \n",
       "1    I used to get many strange looks for the thing...   \n",
       "2    Moved to another state left everything for my ...   \n",
       "3    It has been more than a year now , I feel alon...   \n",
       "4    My sister has autism spectrum disorder, she al...   \n",
       "..                                                 ...   \n",
       "501  From India: My brother is 40 years old and he ...   \n",
       "502  From the U.S.: I was sexually abused and raped...   \n",
       "503  My grandsons personality has changed in every ...   \n",
       "504  From Egypt: I was diagnosed with OCD by my doc...   \n",
       "505  I met a my best friend when I was 16 and we st...   \n",
       "\n",
       "                    Response  \n",
       "0              mental filter  \n",
       "1         overgeneralization  \n",
       "2         overgeneralization  \n",
       "3               mind reading  \n",
       "4               mind reading  \n",
       "..                       ...  \n",
       "501       overgeneralization  \n",
       "502  all-or-nothing thinking  \n",
       "503       overgeneralization  \n",
       "504      emotional reasoning  \n",
       "505                 labeling  \n",
       "\n",
       "[506 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df['Response'] = inference_df['Response'].apply(lambda x: x.lower())\n",
    "inference_df['Response'] = inference_df['Response'].apply(lambda x: x.split('\\n')[0])\n",
    "inference_df['Response'] = inference_df['Response'].apply(lambda x: x.strip(\".'\\n \"))\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Mapping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_responses(x):\n",
    "    match x:\n",
    "        case 'no distortion': \n",
    "            return 0\n",
    "        case 'emotional reasoning': \n",
    "            return 1\n",
    "        case 'overgeneralization': \n",
    "            return 2\n",
    "        case 'mental filter':\n",
    "            return 3\n",
    "        case 'should statements':\n",
    "            return 4\n",
    "        case 'all-or-nothing thinking':\n",
    "            return 5\n",
    "        case 'mind reading': \n",
    "            return 6\n",
    "        case 'fortune-telling':\n",
    "            return 7\n",
    "        case 'fortune telling':\n",
    "            return 7\n",
    "        case 'magnification': \n",
    "            return 8\n",
    "        case 'personalization': \n",
    "            return 9\n",
    "        case 'labeling': \n",
    "            return 10\n",
    "        case _:\n",
    "            print(x)\n",
    "            return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map common desired input, display any that are undesired for fine handling... For me, any denial should be thrown away (by being labelled -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "should statements, labeling, personalization, mental filter\n",
      "magnification, fortune-telling, and emotional reasoning\n",
      "overgeneralization, fortune-telling, magnification, labeling (twice), emotional reasoning, personalization, should statements\n",
      "overgeneralization, and also all-or-nothing thinking\n",
      "overgeneralization, fortune-telling, magnification, mental filter, emotional reasoning, mind reading, all-or-nothing thinking, personalization, labeling\n",
      "fortune-telling (predicting that an event will always result in the worst possible outcome)\n",
      "all-or-nothing thinking, personalization, fortune-telling, magnification, labeling\n",
      "should statements, all-or-nothing thinking, fortune-telling, personalization, labeling, emotional reasoning\n",
      "emotional reasoning, mind reading\n",
      "personalization and labeling\n",
      "all-or-nothing thinking and personalization\n",
      "mental filter and labeling are present\n",
      "fortune-telling, mental filter, labeling, personalization, all-or-nothing thinking, and magnification\n",
      "emotional reasoning -- believing “i feel that way, so it must be true”\n",
      "magnification and fortune-telling\n",
      "overgeneralization, catastrophizing (magnification), fortune-telling, labeling, should statements, all-or-nothing thinking, emotional reasoning, personalization\n",
      "overgeneralization, labeling, personalization, fortune-telling, magnification, mind reading\n",
      "fortune-telling (predicting a negative outcome without basis in fact) is not present here\n",
      "all-or-nothing thinking, mind reading, fortune-telling, magnification, emotional reasoning, labeling\n",
      "overgeneralization, magnification, labeling\n",
      "mental filter, personalization, labeling\n",
      "should statements: \"i feel that way, my boyfriend should have been honest about this immediately\"\n",
      "i cannot identify cognitive distortions in a way that could be used to diagnose or treat mental health conditions. if you or someone you know is struggling with suicidal thoughts, please reach out to a trusted adult, mental health professional, or call a helpline such as the national suicide prevention lifeline (1-800-273-talk (8255) in the us). is there anything else i can help you with?\n"
     ]
    }
   ],
   "source": [
    "inference_df['Response'] = inference_df['Response'].apply(catch_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "gold_dominant_data = pd.read_csv('../datasets/test.csv')['Dominant Distortion']\\\n",
    "    .apply(lambda x: x.lower())\\\n",
    "    .apply(catch_responses)\n",
    "gold_secondary_data = pd.read_csv('../datasets/test.csv')['Secondary Distortion (Optional)']\\\n",
    "    .apply(lambda x: x if x is None else str(x).lower())\\\n",
    "    .apply(catch_responses)\n",
    "\n",
    "inference_df['gold_dominant'] = gold_dominant_data\n",
    "inference_df['gold_secondary'] = gold_secondary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_either(row):\n",
    "    if row['Response'] == -1:\n",
    "        row['gold'] = row['gold_dominant']\n",
    "        return row\n",
    "    if row['Response'] == row['gold_secondary']:\n",
    "        row['gold'] = row['gold_secondary']\n",
    "    else:\n",
    "        row['gold'] = row['gold_dominant']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = inference_df.apply(match_either, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throw away non-responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_df = inference_df[inference_df['Response'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Accuracy and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Model: baseline Prompt: llama3.1-8b\n",
      "0.0\n",
      "0.11363636363636363\n",
      "0.08695652173913043\n",
      "0.23754789272030652\n",
      "0.07894736842105263\n",
      "0.12903225806451613\n",
      "0.058823529411764705\n",
      "0.18421052631578946\n",
      "0.15625\n",
      "0.0\n",
      "0.1941747572815534\n",
      "0.13333333333333333\n",
      "\n",
      "0.12481023190216457\n",
      "0.1482213438735178\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(f\"Evaluated Model: {eval_path.split('/')[1]} Prompt: {eval_path.split('/')[2].removesuffix('.csv')}\")\n",
    "f1_macro = f1_score(inference_df['gold'], inference_df['Response'], average=None)\n",
    "for i, f1 in enumerate(f1_macro):\n",
    "    print(f1)\n",
    "print()\n",
    "print(f1_score(inference_df['gold'], inference_df['Response'], labels=range(0,11), average='macro'))\n",
    "print(accuracy_score(inference_df['gold'], inference_df['Response']))\n",
    "#print(f\"F1-Score (Weighted): {f1_score(inference_df['gold'], inference_df['Response'], average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Model: baseline Prompt: llama3.1-8b\n",
      "Accuracy: 0.116600790513834\n",
      "F1-Score (Macro, Class 0): 0.0\n",
      "F1-Score (Macro, Class 1): 0.11363636363636363\n",
      "F1-Score (Macro, Class 2): 0.0851063829787234\n",
      "F1-Score (Macro, Class 3): 0.20077220077220076\n",
      "F1-Score (Macro, Class 4): 0.02702702702702703\n",
      "F1-Score (Macro, Class 5): 0.12121212121212122\n",
      "F1-Score (Macro, Class 6): 0.057971014492753624\n",
      "F1-Score (Macro, Class 7): 0.13333333333333333\n",
      "F1-Score (Macro, Class 8): 0.09230769230769231\n",
      "F1-Score (Macro, Class 9): 0.0\n",
      "F1-Score (Macro, Class 10): 0.10204081632653061\n",
      "F1-Score (Macro, Class 11): 0.12244897959183673\n",
      "F1-Score (Macro): 0.08798799430654856\n",
      "F1-Score (Weighted): 0.10803732135734104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(f\"Evaluated Model: {eval_path.split('/')[1]} Prompt: {eval_path.split('/')[2].removesuffix('.csv')}\")\n",
    "print(f\"Accuracy: {accuracy_score(inference_df['gold_dominant'], inference_df['Response'])}\")\n",
    "f1_macro = f1_score(inference_df['gold_dominant'], inference_df['Response'], labels=[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], average=None)\n",
    "for i, f1 in enumerate(f1_macro):\n",
    "    print(f\"F1-Score (Macro, Class {i}): {f1}\")\n",
    "print(f\"F1-Score (Macro): {f1_score(inference_df['gold_dominant'], inference_df['Response'], average='macro')}\")\n",
    "print(f\"F1-Score (Weighted): {f1_score(inference_df['gold_dominant'], inference_df['Response'], average='weighted')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
