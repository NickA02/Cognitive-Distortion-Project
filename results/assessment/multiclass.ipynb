{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result Cleaning and Evaluation for Binary Cognitive Distortion Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#Make this your results directory\n",
    "os.chdir('..')\n",
    "eval_path = 'multiclass/enhanced-definition/gemma2-27b/zero-shot.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My husband works a lot which really helps our ...</td>\n",
       "      <td>Mental Filter \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I used to get many strange looks for the thing...</td>\n",
       "      <td>No Distortion \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Moved to another state left everything for my ...</td>\n",
       "      <td>Emotional Reasoning \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It has been more than a year now , I feel alon...</td>\n",
       "      <td>Personalization \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My sister has autism spectrum disorder, she al...</td>\n",
       "      <td>Mind Reading \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>From India: My brother is 40 years old and he ...</td>\n",
       "      <td>Overgeneralization \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>From the U.S.: I was sexually abused and raped...</td>\n",
       "      <td>No Distortion \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>My grandsons personality has changed in every ...</td>\n",
       "      <td>Emotional Reasoning \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>From Egypt: I was diagnosed with OCD by my doc...</td>\n",
       "      <td>Should Statements \\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>505</td>\n",
       "      <td>I met a my best friend when I was 16 and we st...</td>\n",
       "      <td>Should Statements \\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Prompt  \\\n",
       "0             0  My husband works a lot which really helps our ...   \n",
       "1             1  I used to get many strange looks for the thing...   \n",
       "2             2  Moved to another state left everything for my ...   \n",
       "3             3  It has been more than a year now , I feel alon...   \n",
       "4             4  My sister has autism spectrum disorder, she al...   \n",
       "..          ...                                                ...   \n",
       "501         501  From India: My brother is 40 years old and he ...   \n",
       "502         502  From the U.S.: I was sexually abused and raped...   \n",
       "503         503  My grandsons personality has changed in every ...   \n",
       "504         504  From Egypt: I was diagnosed with OCD by my doc...   \n",
       "505         505  I met a my best friend when I was 16 and we st...   \n",
       "\n",
       "                   Response  \n",
       "0          Mental Filter \\n  \n",
       "1          No Distortion \\n  \n",
       "2    Emotional Reasoning \\n  \n",
       "3        Personalization \\n  \n",
       "4           Mind Reading \\n  \n",
       "..                      ...  \n",
       "501   Overgeneralization \\n  \n",
       "502        No Distortion \\n  \n",
       "503  Emotional Reasoning \\n  \n",
       "504    Should Statements \\n  \n",
       "505    Should Statements \\n  \n",
       "\n",
       "[506 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "eval_path = 'multiclass/baseline/gemma2-27b/zero-shot.csv'\n",
    "inference_df = pd.read_csv(eval_path)\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fix Common Variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Prompt</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My husband works a lot which really helps our ...</td>\n",
       "      <td>mental filter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>I used to get many strange looks for the thing...</td>\n",
       "      <td>no distortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Moved to another state left everything for my ...</td>\n",
       "      <td>emotional reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>It has been more than a year now , I feel alon...</td>\n",
       "      <td>personalization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>My sister has autism spectrum disorder, she al...</td>\n",
       "      <td>mind reading</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>From India: My brother is 40 years old and he ...</td>\n",
       "      <td>overgeneralization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>502</td>\n",
       "      <td>From the U.S.: I was sexually abused and raped...</td>\n",
       "      <td>no distortion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>503</td>\n",
       "      <td>My grandsons personality has changed in every ...</td>\n",
       "      <td>emotional reasoning</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>504</td>\n",
       "      <td>From Egypt: I was diagnosed with OCD by my doc...</td>\n",
       "      <td>should statements</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>505</td>\n",
       "      <td>I met a my best friend when I was 16 and we st...</td>\n",
       "      <td>should statements</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                             Prompt  \\\n",
       "0             0  My husband works a lot which really helps our ...   \n",
       "1             1  I used to get many strange looks for the thing...   \n",
       "2             2  Moved to another state left everything for my ...   \n",
       "3             3  It has been more than a year now , I feel alon...   \n",
       "4             4  My sister has autism spectrum disorder, she al...   \n",
       "..          ...                                                ...   \n",
       "501         501  From India: My brother is 40 years old and he ...   \n",
       "502         502  From the U.S.: I was sexually abused and raped...   \n",
       "503         503  My grandsons personality has changed in every ...   \n",
       "504         504  From Egypt: I was diagnosed with OCD by my doc...   \n",
       "505         505  I met a my best friend when I was 16 and we st...   \n",
       "\n",
       "                Response  \n",
       "0          mental filter  \n",
       "1          no distortion  \n",
       "2    emotional reasoning  \n",
       "3        personalization  \n",
       "4           mind reading  \n",
       "..                   ...  \n",
       "501   overgeneralization  \n",
       "502        no distortion  \n",
       "503  emotional reasoning  \n",
       "504    should statements  \n",
       "505    should statements  \n",
       "\n",
       "[506 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inference_df['Response'] = inference_df['Response'].apply(lambda x: x.lower())\n",
    "inference_df['Response'] = inference_df['Response'].apply(lambda x: x.split('\\n')[0])\n",
    "inference_df['Response'] = inference_df['Response'].apply(lambda x: x.strip(\".'\\n \"))\n",
    "inference_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Mapping Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def catch_responses(x):\n",
    "    match x:\n",
    "        case 'no distortion': \n",
    "            return 0\n",
    "        case 'emotional reasoning': \n",
    "            return 1\n",
    "        case 'overgeneralization': \n",
    "            return 2\n",
    "        case 'mental filter':\n",
    "            return 3\n",
    "        case 'should statements':\n",
    "            return 4\n",
    "        case 'all-or-nothing thinking':\n",
    "            return 5\n",
    "        case 'mind reading': \n",
    "            return 6\n",
    "        case 'fortune-telling':\n",
    "            return 7\n",
    "        case 'fortune telling':\n",
    "            return 7\n",
    "        case 'magnification': \n",
    "            return 8\n",
    "        case 'personalization': \n",
    "            return 9\n",
    "        case 'labeling': \n",
    "            return 10\n",
    "        case _:\n",
    "            print(x)\n",
    "            return -1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map common desired input, display any that are undesired for fine handling... For me, any denial should be thrown away (by being labelled -1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimization\n",
      "confirmation bias\n"
     ]
    }
   ],
   "source": [
    "inference_df['Response'] = inference_df['Response'].apply(catch_responses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gather Gold Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n",
      "nan\n"
     ]
    }
   ],
   "source": [
    "gold_dominant_data = pd.read_csv('../datasets/test.csv')['Dominant Distortion']\\\n",
    "    .apply(lambda x: x.lower())\\\n",
    "    .apply(catch_responses)\n",
    "gold_secondary_data = pd.read_csv('../datasets/test.csv')['Secondary Distortion (Optional)']\\\n",
    "    .apply(lambda x: x if x is None else str(x).lower())\\\n",
    "    .apply(catch_responses)\n",
    "\n",
    "inference_df['gold_dominant'] = gold_dominant_data\n",
    "inference_df['gold_secondary'] = gold_secondary_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_either(row):\n",
    "    if row['Response'] == -1:\n",
    "        row['gold'] = row['gold_dominant']\n",
    "        return row\n",
    "    if row['Response'] == row['gold_secondary']:\n",
    "        row['gold'] = row['gold_secondary']\n",
    "    else:\n",
    "        row['gold'] = row['gold_dominant']\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_df = inference_df.apply(match_either, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Throw away non-responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inference_df = inference_df[inference_df['Response'] != -1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Accuracy and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Model: baseline Prompt: gemma2-27b\n",
      "0.0\n",
      "0.2857142857142857\n",
      "0.11764705882352941\n",
      "0.25\n",
      "0.08163265306122448\n",
      "0.11570247933884298\n",
      "0.14705882352941177\n",
      "0.3779527559055118\n",
      "0.2857142857142857\n",
      "0.1694915254237288\n",
      "0.22950819672131148\n",
      "0.25\n",
      "\n",
      "0.21003836947564836\n",
      "0.22924901185770752\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(f\"Evaluated Model: {eval_path.split('/')[1]} Prompt: {eval_path.split('/')[2].removesuffix('.csv')}\")\n",
    "f1_macro = f1_score(inference_df['gold'], inference_df['Response'], average=None)\n",
    "for i, f1 in enumerate(f1_macro):\n",
    "    print(f1)\n",
    "print()\n",
    "print(f1_score(inference_df['gold'], inference_df['Response'], labels=range(0,11), average='macro'))\n",
    "print(accuracy_score(inference_df['gold'], inference_df['Response']))\n",
    "#print(f\"F1-Score (Weighted): {f1_score(inference_df['gold'], inference_df['Response'], average='weighted')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluated Model: baseline Prompt: gemma2-27b\n",
      "Accuracy: 0.19960474308300397\n",
      "F1-Score (Macro, Class 0): 0.0\n",
      "F1-Score (Macro, Class 1): 0.2857142857142857\n",
      "F1-Score (Macro, Class 2): 0.08955223880597014\n",
      "F1-Score (Macro, Class 3): 0.22641509433962265\n",
      "F1-Score (Macro, Class 4): 0.041666666666666664\n",
      "F1-Score (Macro, Class 5): 0.1\n",
      "F1-Score (Macro, Class 6): 0.14084507042253522\n",
      "F1-Score (Macro, Class 7): 0.3333333333333333\n",
      "F1-Score (Macro, Class 8): 0.19718309859154928\n",
      "F1-Score (Macro, Class 9): 0.06896551724137931\n",
      "F1-Score (Macro, Class 10): 0.2\n",
      "F1-Score (Macro, Class 11): 0.225\n",
      "F1-Score (Macro): 0.1590562754262785\n",
      "F1-Score (Weighted): 0.21563753713680056\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "print(f\"Evaluated Model: {eval_path.split('/')[1]} Prompt: {eval_path.split('/')[2].removesuffix('.csv')}\")\n",
    "print(f\"Accuracy: {accuracy_score(inference_df['gold_dominant'], inference_df['Response'])}\")\n",
    "f1_macro = f1_score(inference_df['gold_dominant'], inference_df['Response'], labels=[-1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], average=None)\n",
    "for i, f1 in enumerate(f1_macro):\n",
    "    print(f\"F1-Score (Macro, Class {i}): {f1}\")\n",
    "print(f\"F1-Score (Macro): {f1_score(inference_df['gold_dominant'], inference_df['Response'], average='macro')}\")\n",
    "print(f\"F1-Score (Weighted): {f1_score(inference_df['gold_dominant'], inference_df['Response'], average='weighted')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
