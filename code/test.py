import subprocess
print("Running gemma enhanced-definition multiclass 0")
subprocess.call("python3 code/generate_response.py gemma2-27b enhanced-definition multiclass 0", shell=True)
print("Running gemma more-enhanced-definition multiclass 0")
subprocess.call("python3 code/generate_response.py gemma2-27b more-enhanced-definition multiclass 0", shell=True)
print("Running gemma baseline multiclass 0")
subprocess.call("python3 code/generate_response.py gemma2-27b baseline multiclass 0", shell=True)
print("Running gemma expert multiclass 0")
subprocess.call("python3 code/generate_response.py gemma2-27b expert multiclass 0", shell=True)
print("Running gemma expert-explanation multiclass 0")
subprocess.call("python3 code/generate_response.py gemma2-27b expert-explanation multiclass 0", shell=True)
print("Running gemma explanation multiclass 0")
subprocess.call("python3 code/generate_response.py gemma2-27b explanation multiclass 0", shell=True)
print("Running gemma baseline heirarchy 0")
subprocess.call("python3 code/generate_response.py gemma2-27b baseline heirarchy 0", shell=True)
print("Running gemma expert heirarchy 0")
subprocess.call("python3 code/generate_response.py gemma2-27b expert heirarchy 0", shell=True)
print("Running gemma expert-explanation heirarchy 0")
subprocess.call("python3 code/generate_response.py gemma2-27b expert-explanation heirarchy 0", shell=True)
print("Running gemma explanation heirarchy 0")
subprocess.call("python3 code/generate_response.py gemma2-27b explanation heirarchy 0", shell=True)
print("Running llama enhanced-definition multiclass 0")
subprocess.call("python3 code/generate_response.py llama3.1-8b enhanced-definition multiclass 0", shell=True)
subprocess.call("python3 code/generate_response.py llama3.1-8b more-enhanced-definition multiclass 0", shell=True)
print("Running llama baseline multiclass 0")
subprocess.call("python3 code/generate_response.py llama3.1-8b baseline multiclass 0", shell=True)
print("Running llama expert multiclass 0")
subprocess.call("python3 code/generate_response.py llama3.1-8b expert multiclass 0", shell=True)
print("Running llama expert-explanation multiclass 0")
subprocess.call("python3 code/generate_response.py llama3.1-8b expert-explanation multiclass 0", shell=True) 
print("Running llama explanation multiclass 0")   
subprocess.call("python3 code/generate_response.py llama3.1-8b explanation multiclass 0", shell=True)
